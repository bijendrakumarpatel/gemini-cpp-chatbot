

# ğŸš€ Gemini Chatbot (C++ + Crow)

This project is a lightweight **AI chatbot backend** written in **C++** using [Crow](https://github.com/CrowCpp/crow) (a C++ web framework), [cURL](https://curl.se/libcurl/), and [nlohmann/json](https://github.com/nlohmann/json).
It connects to **Google Gemini API** and provides a simple REST API for chatting with an AI assistant.

---

## âœ¨ Features

* âœ… REST API built with **Crow**
* âœ… Persistent **multi-turn conversation history** per session
* âœ… Uses **Google Gemini API** (`gemini-1.5-flash`) for AI responses
* âœ… Thread-safe session management with `std::mutex`
* âœ… Simple frontend support (serves `index.html`)

---

## ğŸ› ï¸ Requirements

* **C++17 or later**
* [Crow](https://github.com/CrowCpp/crow)
* [libcurl](https://curl.se/libcurl/)
* [nlohmann/json](https://github.com/nlohmann/json)

### Install on Ubuntu/Debian

```bash
sudo apt-get update
sudo apt-get install g++ cmake libcurl4-openssl-dev
```

### Install on Windows (via vcpkg)

```bash
vcpkg install curl nlohmann-json
```

---

## âš¡ Setup & Run

### 1. Clone the repo

```bash
git clone https://github.com/your-username/gemini-cpp-chatbot.git
cd gemini-cpp-chatbot
```

### 2. Set your Gemini API Key

Edit `main.cpp` and replace:

```cpp
const string API_KEY = "YOUR_API_KEY_HERE";
```

You can get an API key from [Google AI Studio](https://aistudio.google.com/).

### 3. Build

```bash
g++ main.cpp -o chatbot -lcurl -pthread
```

### 4. Run the server

```bash
./chatbot
```

The server will start on:
ğŸ‘‰ **[http://localhost:18080/](http://localhost:18080/)**

---

## ğŸ”— API Usage

### 1. Chat Endpoint

**POST** `/api/chat`

#### Request JSON

```json
{
  "session": "user123",
  "message": "Hello, AI!"
}
```

#### Response JSON

```json
{
  "reply": "Hi there! How can I help you?",
  "session": "user123"
}
```

* `session` â†’ keeps track of conversation history
* `message` â†’ user input
* `reply` â†’ AI response

---

## ğŸ¨ Frontend

You can serve a simple **`index.html`** at `/`.
Just put your HTML/JS frontend in the project root and it will be returned by the backend.

---

## ğŸ“Œ Example Request (cURL)

```bash
curl -X POST http://localhost:18080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"session":"demo123","message":"Tell me a joke"}'
```

---

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ main.cpp        # C++ backend server
â”œâ”€â”€ index.html      # Simple frontend (optional)
â”œâ”€â”€ README.md       # Documentation
```

---

## ğŸš€ Future Improvements

* ğŸ”— Add **WebSocket** support for real-time chat
* ğŸ” Add **user authentication** and DB-based session storage
* ğŸ³ Deploy with **Docker**
* ğŸ¨ Enhance frontend UI with **React/Vue**

---

## ğŸ“œ License

**MIT License** â€“ feel free to use and modify.

---
